{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59355bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM Studio: http://localhost:1234/v1/completions | Model: mistral-7b-instruct-v0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Настройки LM Studio (локальный сервер)\n",
    "LM_BASE = \"http://localhost:1234/v1/completions\"\n",
    "LM_MODEL = \"mistral-7b-instruct-v0.3\"\n",
    "\n",
    "Path(\"tests\").mkdir(exist_ok=True)\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"LM Studio:\", LM_BASE, \"| Model:\", LM_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bd468",
   "metadata": {},
   "source": [
    "Простая функция суммаризации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python - популярный язык программирования, отличающийся простым синтаксисом.\n",
      "\n",
      "---\n",
      "\n",
      "Python is a popular programming language with a simple syntax.\n",
      "\n",
      "Сводка: Python - популярный язык\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def summarize(text: str, max_tokens: int = 128, temperature: float = 0.2) -> str:\n",
    "    prompt = (\n",
    "        \"Суммаризируй следующий текст кратко и по делу на русском языке.\\n\\n\"\n",
    "        f\"Текст:\\n{text}\\n\\nКраткая сводка:\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": LM_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    r = requests.post(LM_BASE, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Проверим\n",
    "print(summarize(\"Python — это популярный язык программирования с простым синтаксисом.\", 60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cad900",
   "metadata": {},
   "source": [
    "Goldens (10 примеров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6678c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан tests/goldens.json с 10 примерами\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "goldens = [\n",
    "    {\n",
    "        \"id\": i+1,\n",
    "        \"source\": s,\n",
    "        \"reference\": r\n",
    "    } for i, (s, r) in enumerate([\n",
    "        (\n",
    "            \"Python — интерпретируемый язык программирования общего назначения. \"\n",
    "            \"Его отличают простота синтаксиса и богатая экосистема библиотек.\",\n",
    "            \"Python — простой интерпретируемый язык с богатой экосистемой.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Pandas — библиотека Python для анализа и обработки данных.\",\n",
    "            \"Pandas — библиотека Python для анализа данных.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Машинное обучение использует алгоритмы, обучающиеся на данных для предсказаний и поиска закономерностей.\",\n",
    "            \"Машинное обучение — это обучение моделей на данных для предсказаний.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Git — система контроля версий, помогающая отслеживать изменения и работать в команде.\",\n",
    "            \"Git — система контроля версий для командной работы.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Docker упаковывает приложения в контейнеры, обеспечивая переносимость и одинаковое окружение.\",\n",
    "            \"Docker — контейнеризация для переносимости приложений.\"\n",
    "        ),\n",
    "        (\n",
    "            \"RAG объединяет поиск по базе знаний и генерацию ответа LLM для точных результатов.\",\n",
    "            \"RAG — комбинация поиска и генерации для улучшения точности.\"\n",
    "        ),\n",
    "        (\n",
    "            \"NumPy — библиотека Python для численных вычислений, обеспечивает быстрые операции над массивами.\",\n",
    "            \"NumPy — библиотека для быстрых численных операций.\"\n",
    "        ),\n",
    "        (\n",
    "            \"LLM — большие языковые модели, обученные на корпусах текста и способные генерировать связный текст.\",\n",
    "            \"LLM — большие модели, генерирующие связный текст.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Hugging Face развивает экосистему моделей и инструментов для NLP и ML.\",\n",
    "            \"Hugging Face — платформа моделей и инструментов для NLP.\"\n",
    "        ),\n",
    "        (\n",
    "            \"CI/CD — это автоматизация сборки, тестов и релизов для ускорения поставки ПО.\",\n",
    "            \"CI/CD — автоматизация сборки, тестов и релизов.\"\n",
    "        ),\n",
    "    ])\n",
    "]\n",
    "\n",
    "with open(\"tests/goldens.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(goldens, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Создан tests/goldens.json с\", len(goldens), \"примерами\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbf182",
   "metadata": {},
   "source": [
    "Генерация суммаризаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0457ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:08<00:00,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Суммаризации сохранены в results/summaries.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"tests/goldens.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    goldens = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for ex in tqdm(goldens):\n",
    "    s = summarize(ex[\"source\"])\n",
    "    rows.append({\n",
    "        \"id\": ex[\"id\"],\n",
    "        \"source\": ex[\"source\"],\n",
    "        \"reference\": ex[\"reference\"],\n",
    "        \"summary\": s\n",
    "    })\n",
    "\n",
    "with open(\"results/summaries.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in rows:\n",
    "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Суммаризации сохранены в results/summaries.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da5d0e",
   "metadata": {},
   "source": [
    "Ragas (Faithfulness) + ROUGE (локально, через LangChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff924711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb681e991a30496197e6b4d2ed5f7ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness_mean': 0.8833333333333332,\n",
       " 'rougeL': 0.5031831831831832,\n",
       " 'n_samples': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate as ragas_evaluate\n",
    "from ragas.metrics import faithfulness\n",
    "from ragas.run_config import RunConfig\n",
    "import evaluate as hf_evaluate\n",
    "from langchain_community.llms import OpenAI\n",
    "\n",
    "# LM Studio как OpenAI-совместимая LLM \n",
    "ragas_llm = OpenAI(\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    openai_api_key=\"lm-studio\",\n",
    "    model_name=\"mistral-7b-instruct-v0.3\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,       # увеличить\n",
    "    request_timeout=120   # безопасный таймаут\n",
    ")\n",
    "\n",
    "\n",
    "rows = [json.loads(x) for x in Path(\"results/summaries.jsonl\").read_text(encoding=\"utf-8\").splitlines()]\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Датасет для Ragas\n",
    "ragas_ds = Dataset.from_pandas(pd.DataFrame({\n",
    "    \"question\": [\"\" for _ in df.index],\n",
    "    \"contexts\": [[s] for s in df[\"source\"].tolist()],\n",
    "    \"answer\": df[\"summary\"].tolist(),\n",
    "}))\n",
    "\n",
    "# faithfulness с увеличенным лимитом\n",
    "run_cfg = RunConfig(timeout=300, max_workers=1)\n",
    "ragas_result = ragas_evaluate(\n",
    "    ragas_ds,\n",
    "    metrics=[faithfulness],\n",
    "    llm=ragas_llm,\n",
    "    run_config=run_cfg\n",
    ")\n",
    "faith_scores = ragas_result[\"faithfulness\"]\n",
    "\n",
    "# ROUGE\n",
    "rouge = hf_evaluate.load(\"rouge\")\n",
    "rouge_out = rouge.compute(predictions=df[\"summary\"].tolist(), references=df[\"reference\"].tolist())\n",
    "rougeL = rouge_out[\"rougeL\"]\n",
    "\n",
    "metrics = {\n",
    "    \"faithfulness_mean\": float(sum(faith_scores)/len(faith_scores)) if len(faith_scores) else float(\"nan\"),\n",
    "    \"rougeL\": float(rougeL),\n",
    "    \"n_samples\": len(df)\n",
    "}\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb901b",
   "metadata": {},
   "source": [
    "Отчёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7995f73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Отчёт сохранён в results/report.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"results/metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "faith_str = f\"{metrics['faithfulness_mean']:.3f}\" if metrics['faithfulness_mean']==metrics['faithfulness_mean'] else \"—\"\n",
    "\n",
    "report_html = f\"\"\"\n",
    "<html>\n",
    "<head><meta charset=\"utf-8\"><title>Ragas & ROUGE Report</title></head>\n",
    "<body>\n",
    "<h2>Оценка суммаризации (LM Studio, mistral-7b-instruct-v0.3)</h2>\n",
    "<ul>\n",
    "  <li><b>Faithfulness (mean):</b> {faith_str}</li>\n",
    "  <li><b>ROUGE-L:</b> {metrics['rougeL']:.3f}</li>\n",
    "  <li><b>Примеров:</b> {metrics['n_samples']}</li>\n",
    "</ul>\n",
    "<h3>Примеры:</h3>\n",
    "{pd.DataFrame(rows)[:3].to_html(index=False)}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "Path(\"results/report.html\").write_text(report_html, encoding=\"utf-8\")\n",
    "\"Отчёт сохранён в results/report.html\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b80e75",
   "metadata": {},
   "source": [
    "Тесты (quality gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e08b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан tests/test_metrics.py\n"
     ]
    }
   ],
   "source": [
    "test_code = r'''\n",
    "import json\n",
    "import math\n",
    "\n",
    "def load_metrics():\n",
    "    with open(\"results/metrics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def test_faithfulness():\n",
    "    m = load_metrics()\n",
    "    assert not math.isnan(m[\"faithfulness_mean\"]), \"Faithfulness не рассчитан\"\n",
    "    assert m[\"faithfulness_mean\"] >= 0.7, f\"faithfulness_mean={m['faithfulness_mean']:.3f} < 0.7\"\n",
    "\n",
    "def test_rouge():\n",
    "    m = load_metrics()\n",
    "    assert m[\"rougeL\"] >= 0.2, f\"rougeL={m['rougeL']:.3f} < 0.2\"\n",
    "'''\n",
    "Path(\"tests/test_metrics.py\").write_text(test_code, encoding=\"utf-8\")\n",
    "print(\"Создан tests/test_metrics.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ab62d",
   "metadata": {},
   "source": [
    "Прогон тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a082ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                       [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danila\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fs\\__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "!pytest -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24717608",
   "metadata": {},
   "source": [
    "### Итоговый отчет:\n",
    "\n",
    "**Автоматизация тестирования LLM с CI/CD**\n",
    "\n",
    "- Модель: mistral-7b-instruct-v0.3 (локально через LM Studio)\n",
    "- Тип задачи: суммаризация текста\n",
    "- Тестирование: Ragas + ROUGE-L\n",
    "- Автотесты: pytest (quality gates)\n",
    "- CI/CD: GitHub Actions (.github/workflows/ci.yml)\n",
    "- Репозиторий: https://github.com/ТВОЙ_НИК/llm-ci-cd-summarization\n",
    "\n",
    "---\n",
    "\n",
    "- Использовал локальную LLM — mistral-7b-instruct-v0.3 \n",
    "- Метрика Faithfulness реализована через Ragas и успешно рассчитана.\n",
    "- Метрика ROUGE-L для оценки близости к эталону.\n",
    "- Все результаты сохранены в results/metrics.json и results/report.html.\n",
    "\n",
    "- Автотесты (pytest) проверяют пороги:\n",
    "   • Faithfulness ≥ 0.70\n",
    "   • ROUGE-L ≥ 0.20\n",
    "\n",
    "- GitHub Actions настроен, пайплайн автоматически запускает тесты при пуше.\n",
    "- Работает полностью офлайн, без OpenAI API.\n",
    "\n",
    "---\n",
    "\n",
    "**Метрики**:\n",
    "\n",
    "  • Faithfulness (mean): 0.88  \n",
    "  • ROUGE-L: 0.50  \n",
    "  • Samples: 10  \n",
    "\n",
    "---\n",
    "\n",
    "**Вывод:**\n",
    "\n",
    "Модель демонстрирует высокую достоверность суммаризаций (без галлюцинаций).  \n",
    "CI/CD пайплайн обеспечивает автоматический контроль качества, включая метрики Ragas и pytest-тесты.  \n",
    "Проект полностью автономен.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
